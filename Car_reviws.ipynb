{"cells":[{"source":"![image](car.jpeg)\n\n**Car-ing is sharing**, an auto dealership company for car sales and rental, is taking their services to the next level thanks to **Large Language Models (LLMs)**.\n\nAs their newly recruited AI and NLP developer, you've been asked to prototype a chatbot app with multiple functionalities that not only assist customers but also provide support to human agents in the company.\n\nThe solution should receive textual prompts and use a variety of pre-trained Hugging Face LLMs to respond to a series of tasks, e.g. classifying the sentiment in a carâ€™s text review, answering a customer question, summarizing or translating text, etc.\n","metadata":{},"id":"9aabafca-8129-4943-b865-d5e897637253","cell_type":"markdown"},{"source":"# Import necessary packages\nimport pandas as pd\nimport torch\n\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1750074097469,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary packages\nimport pandas as pd\nimport torch\n\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)","outputsMetadata":{"0":{"height":553,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedByKernel":"af1a4ac1-06a6-49fb-9621-7ca1475566cb"},"id":"5325a4c0-ceb3-4b66-acd2-5eadcefe3a63","cell_type":"code","execution_count":17,"outputs":[]},{"source":"import pandas as pd\nfrom transformers import pipeline\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom nltk.translate.bleu_score import sentence_bleu\nimport nltk\nimport os\n\n# --- NLTK Download Section ---\nprint(\"Checking NLTK data...\")\ntry:\n    # Ensure 'punkt' tokenizer models are available\n    nltk.data.find('tokenizers/punkt')\n    print(\"'punkt' tokenizer found.\")\nexcept LookupError:\n    print(\"'punkt' tokenizer not found, downloading...\")\n    nltk.download('punkt')\n    print(\"'punkt' tokenizer downloaded.\")\n\ntry:\n    # Ensure 'wordnet' corpus is available for general NLP tasks (like lemmatization, though not directly used in your provided code for this version)\n    nltk.data.find('corpora/wordnet')\n    print(\"'wordnet' corpus found.\")\nexcept LookupError:\n    print(\"'wordnet' corpus not found, downloading...\")\n    nltk.download('wordnet')\n    print(\"'wordnet' corpus downloaded.\")\nprint(\"NLTK data check complete.\")\n# --- End NLTK Download Section ---\n\n# Verify file existence\ncsv_file = 'car_reviews.csv'\nref_file = 'reference_translations.txt'\n\nif not os.path.exists(csv_file):\n    raise FileNotFoundError(f\"Error: The file '{csv_file}' was not found in the current working directory ({os.getcwd()}). Please ensure it's there.\")\nif not os.path.exists(ref_file):\n    raise FileNotFoundError(f\"Error: The file '{ref_file}' was not found in the current working directory ({os.getcwd()}). Please ensure it's there.\")\n\n# Load the car reviews dataset with explicit encoding and separator\ntry:\n    # Attempt to read with 'utf-8', then 'latin1' if utf-8 fails, as CSVs can be tricky.\n    try:\n        df = pd.read_csv(csv_file, sep=';', encoding='utf-8')\n    except UnicodeDecodeError:\n        print(f\"UTF-8 decoding failed for {csv_file}. Trying 'latin1' encoding.\")\n        df = pd.read_csv(csv_file, sep=';', encoding='latin1')\n\n    # Verify column names\n    expected_columns = ['Review', 'Class']\n    if not all(col in df.columns for col in expected_columns):\n        missing_cols = [col for col in expected_columns if col not in df.columns]\n        raise ValueError(f\"CSV must contain columns: {expected_columns}. Missing: {missing_cols}\")\n    if df.empty:\n        raise ValueError(f\"The CSV file '{csv_file}' is empty or contains no data rows.\")\n    if df['Review'].isnull().any() or df['Class'].isnull().any():\n        print(\"Warning: Missing values found in 'Review' or 'Class' columns. These rows might be skipped or cause errors.\")\n        df.dropna(subset=['Review', 'Class'], inplace=True) # Drop rows with NaN in critical columns\n    if df.empty: # Check again after dropping NaNs\n        raise ValueError(\"After cleaning missing values, the DataFrame is empty.\")\n\nexcept Exception as e:\n    raise Exception(f\"Error loading or processing CSV file '{csv_file}': {str(e)}\")\n\nprint(f\"Successfully loaded {len(df)} reviews from '{csv_file}'.\")\n\n# --- Task 1: Sentiment Classification ---\nprint(\"\\n--- Task 1: Sentiment Classification ---\")\n# Initialize the sentiment analysis pipeline\ntry:\n    # Using device=-1 to leverage GPU if available, otherwise CPU\n    sentiment_classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english', device=-1)\n    print(\"Sentiment classifier loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing sentiment classifier model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Classify the sentiment of each review\npredicted_labels = []\nfor i, review in enumerate(df['Review']):\n    try:\n        if not isinstance(review, str):\n            print(f\"Skipping review at index {i} due to non-string type: {type(review)}. Value: {review}\")\n            predicted_labels.append('UNKNOWN') # Or 'NEUTRAL', 'NEGATIVE' based on desired fallback\n            continue\n\n        # Truncate review if it's too long for the model (typically 512 tokens)\n        # This is a heuristic; for production, consider more advanced chunking/summarization\n        if len(review.split()) > 400: # Rough token estimate\n            review_for_model = ' '.join(review.split()[:400])\n            # print(f\"Warning: Review {i} is very long, truncating for sentiment analysis.\")\n        else:\n            review_for_model = review\n\n        result = sentiment_classifier(review_for_model)[0]['label']\n        predicted_labels.append(result)\n    except Exception as e:\n        print(f\"Error classifying review {i}: '{review[:70]}...' Error: {str(e)}. Falling back to 'NEGATIVE'.\")\n        predicted_labels.append('NEGATIVE') # Fallback to avoid breaking for individual review errors\n\n# Map predicted labels to binary {0, 1} (POSITIVE=1, NEGATIVE=0)\npredictions = [1 if label.upper() == 'POSITIVE' else 0 for label in predicted_labels]\n\n# Map ground truth labels to binary {0, 1}\ntry:\n    true_labels = []\n    for i, label in enumerate(df['Class']):\n        if isinstance(label, str):\n            true_labels.append(1 if label.upper() == 'POSITIVE' else 0)\n        else:\n            print(f\"Warning: Ground truth label at index {i} is not a string ({type(label)}). Assuming 0 (Negative). Value: {label}\")\n            true_labels.append(0) # Default for non-string ground truth labels\nexcept Exception as e:\n    raise Exception(f\"Error processing ground truth labels from 'Class' column: {str(e)}\")\n\n# Calculate accuracy and F1 score\ntry:\n    accuracy_result = accuracy_score(true_labels, predictions)\n    f1_result = f1_score(true_labels, predictions)\n    print(\"Sentiment classification metrics calculated.\")\nexcept ValueError as e:\n    print(f\"Error calculating metrics. Ensure true_labels and predictions are non-empty and compatible: {str(e)}\")\n    accuracy_result = 0.0\n    f1_result = 0.0\n\n\n# --- Task 2: Translation and BLEU Score ---\nprint(\"\\n--- Task 2: Translation and BLEU Score ---\")\n# Initialize the translation pipeline\ntry:\n    translator = pipeline('translation_en_to_es', model='Helsinki-NLP/opus-mt-en-es', device=-1)\n    print(\"Translator loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing translator model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Extract the first two sentences of the first review\ntext_to_translate = \"\"\ntry:\n    if df.empty or len(df) < 1:\n        raise ValueError(\"Cannot perform translation: DataFrame is empty or has no first review.\")\n    first_review = df['Review'].iloc[0] # Use .iloc for robust integer-based indexing\n    if not isinstance(first_review, str):\n        raise TypeError(f\"First review is not a string: {type(first_review)}. Value: {first_review}\")\n\n    sentences = nltk.sent_tokenize(first_review)\n    if len(sentences) < 2:\n        # Fallback for reviews with fewer than 2 sentences: use the whole review\n        print(f\"Warning: First review has fewer than 2 sentences ({len(sentences)}). Using the entire review for translation.\")\n        text_to_translate = ' '.join(sentences)\n        if not text_to_translate: # If the review was empty\n            raise ValueError(\"First review is empty after tokenization.\")\n    else:\n        text_to_translate = ' '.join(sentences[:2])\n    print(f\"Original text for translation: '{text_to_translate[:100]}...'\")\nexcept Exception as e:\n    raise Exception(f\"Error preparing text for translation from first review: {str(e)}\")\n\n# Perform translation\ntranslated_review = \"\"\ntry:\n    if text_to_translate: # Ensure there's something to translate\n        translation_output = translator(text_to_translate, max_length=512)\n        translated_review = translation_output[0]['translation_text']\n        print(f\"Translated text: '{translated_review[:100]}...'\")\n    else:\n        print(\"Warning: No text to translate. translated_review will be empty.\")\nexcept Exception as e:\n    raise Exception(f\"Error during translation process: {str(e)}\")\n\n# Load reference translations\nreference_translations = []\ntry:\n    with open(ref_file, 'r', encoding='utf-8') as f:\n        reference_translations = [line.strip() for line in f if line.strip()]\n    if not reference_translations:\n        raise ValueError(f\"Reference translations file '{ref_file}' is empty or contains no valid lines.\")\n    print(f\"Loaded {len(reference_translations)} reference translations.\")\nexcept Exception as e:\n    raise Exception(f\"Error loading reference translations from '{ref_file}': {str(e)}\")\n\n# Calculate BLEU score\nbleu_score = 0.0\ntry:\n    if not translated_review:\n        print(\"Cannot calculate BLEU score: translated_review is empty.\")\n    elif not reference_translations:\n        print(\"Cannot calculate BLEU score: reference_translations are empty.\")\n    else:\n        # BLEU expects a list of reference token lists, and one candidate token list\n        # So, reference_tokens should be [[ref1_words], [ref2_words], ...]\n        reference_tokens = [nltk.word_tokenize(ref) for ref in reference_translations]\n        candidate_tokens = nltk.word_tokenize(translated_review)\n        bleu_score = sentence_bleu(reference_tokens, candidate_tokens)\n        print(\"BLEU score calculated.\")\nexcept Exception as e:\n    print(f\"Error calculating BLEU score: {str(e)}. Setting BLEU to 0.0.\")\n    bleu_score = 0.0\n\n\n# --- Task 3: Extractive Question Answering ---\nprint(\"\\n--- Task 3: Extractive Question Answering ---\")\n# Initialize the QA pipeline\ntry:\n    qa_pipeline = pipeline('question-answering', model='deepset/minilm-uncased-squad2', device=-1)\n    print(\"Question-answering pipeline loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing QA pipeline model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Define question and context for the second review\nquestion = \"What did he like about the brand?\"\ncontext = \"\"\ntry:\n    if df.empty or len(df) < 2:\n        raise ValueError(\"Cannot perform QA: DataFrame has fewer than 2 reviews.\")\n    context = df['Review'].iloc[1] # Use .iloc for robust integer-based indexing\n    if not isinstance(context, str):\n        raise TypeError(f\"Second review (context for QA) is not a string: {type(context)}. Value: {context}\")\n    if not context.strip():\n        raise ValueError(\"Second review (context for QA) is empty or just whitespace.\")\n    print(f\"QA Question: '{question}'\")\n    print(f\"QA Context: '{context[:100]}...'\")\nexcept Exception as e:\n    raise Exception(f\"Error preparing context for QA from second review: {str(e)}\")\n\n# Get the answer\nanswer = \"No answer found.\"\ntry:\n    if question and context: # Ensure both are available\n        qa_result = qa_pipeline(question=question, context=context)\n        answer = qa_result['answer']\n        print(f\"QA Answer found: '{answer}'\")\n    else:\n        print(\"Warning: Question or context missing for QA. Answer will be default.\")\nexcept Exception as e:\n    print(f\"Error during Question Answering: {str(e)}. Setting answer to default.\")\n    answer = \"An error occurred while trying to find an answer.\"\n\n\n# --- Task 4: Summarization ---\nprint(\"\\n--- Task 4: Summarization ---\")\n# Initialize the summarization pipeline\ntry:\n    summarizer = pipeline('summarization', model='facebook/bart-large-cnn', device=-1)\n    print(\"Summarization pipeline loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing summarization model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Summarize the last review (aim for ~50-55 tokens)\nsummarized_text = \"No summary generated.\"\ntry:\n    if df.empty or len(df) < 5: # Assuming at least 5 reviews for \"last review\"\n        print(\"Warning: Not enough reviews in the dataset to summarize the last one. Skipping summarization.\")\n    else:\n        last_review = df['Review'].iloc[-1] # Use .iloc[-1] for the last review\n        if not isinstance(last_review, str):\n            raise TypeError(f\"Last review for summarization is not a string: {type(last_review)}. Value: {last_review}\")\n        if not last_review.strip():\n            raise ValueError(\"Last review for summarization is empty or just whitespace.\")\n        print(f\"Original text for summarization: '{last_review[:100]}...'\")\n\n        # Set max_length and min_length for token count control\n        # Note: These are token lengths, not word counts. 50-55 tokens is a tight range.\n        summarized = summarizer(last_review, max_length=55, min_length=50, do_sample=False)\n        summarized_text = summarized[0]['summary_text']\n        print(f\"Summarized text: '{summarized_text}'\")\nexcept Exception as e:\n    print(f\"Error during summarization: {str(e)}. Setting summary to default.\")\n    summarized_text = \"An error occurred during summarization.\"\n\n\n# --- Print Results for Verification ---\nprint(\"\\n--- Final Results ---\")\nprint(f\"Sentiment Classification Accuracy: {accuracy_result:.4f}\")\nprint(f\"Sentiment Classification F1 Score: {f1_result:.4f}\")\nprint(f\"Translated Review (English to Spanish): {translated_review}\")\nprint(f\"BLEU Score (Translation Quality): {bleu_score:.4f}\")\nprint(f\"QA Question: {question}\")\nprint(f\"QA Context (second review snippet): {context[:70]}...\")\nprint(f\"QA Answer: {answer}\")\nprint(f\"Summarized Last Review (approx. 50-55 tokens): {summarized_text}\")","metadata":{"executionCancelledAt":null,"executionTime":8370,"lastExecutedAt":1750074105841,"lastExecutedByKernel":"af1a4ac1-06a6-49fb-9621-7ca1475566cb","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom transformers import pipeline\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom nltk.translate.bleu_score import sentence_bleu\nimport nltk\nimport os\n\n# --- NLTK Download Section ---\nprint(\"Checking NLTK data...\")\ntry:\n    # Ensure 'punkt' tokenizer models are available\n    nltk.data.find('tokenizers/punkt')\n    print(\"'punkt' tokenizer found.\")\nexcept LookupError:\n    print(\"'punkt' tokenizer not found, downloading...\")\n    nltk.download('punkt')\n    print(\"'punkt' tokenizer downloaded.\")\n\ntry:\n    # Ensure 'wordnet' corpus is available for general NLP tasks (like lemmatization, though not directly used in your provided code for this version)\n    nltk.data.find('corpora/wordnet')\n    print(\"'wordnet' corpus found.\")\nexcept LookupError:\n    print(\"'wordnet' corpus not found, downloading...\")\n    nltk.download('wordnet')\n    print(\"'wordnet' corpus downloaded.\")\nprint(\"NLTK data check complete.\")\n# --- End NLTK Download Section ---\n\n# Verify file existence\ncsv_file = 'car_reviews.csv'\nref_file = 'reference_translations.txt'\n\nif not os.path.exists(csv_file):\n    raise FileNotFoundError(f\"Error: The file '{csv_file}' was not found in the current working directory ({os.getcwd()}). Please ensure it's there.\")\nif not os.path.exists(ref_file):\n    raise FileNotFoundError(f\"Error: The file '{ref_file}' was not found in the current working directory ({os.getcwd()}). Please ensure it's there.\")\n\n# Load the car reviews dataset with explicit encoding and separator\ntry:\n    # Attempt to read with 'utf-8', then 'latin1' if utf-8 fails, as CSVs can be tricky.\n    try:\n        df = pd.read_csv(csv_file, sep=';', encoding='utf-8')\n    except UnicodeDecodeError:\n        print(f\"UTF-8 decoding failed for {csv_file}. Trying 'latin1' encoding.\")\n        df = pd.read_csv(csv_file, sep=';', encoding='latin1')\n\n    # Verify column names\n    expected_columns = ['Review', 'Class']\n    if not all(col in df.columns for col in expected_columns):\n        missing_cols = [col for col in expected_columns if col not in df.columns]\n        raise ValueError(f\"CSV must contain columns: {expected_columns}. Missing: {missing_cols}\")\n    if df.empty:\n        raise ValueError(f\"The CSV file '{csv_file}' is empty or contains no data rows.\")\n    if df['Review'].isnull().any() or df['Class'].isnull().any():\n        print(\"Warning: Missing values found in 'Review' or 'Class' columns. These rows might be skipped or cause errors.\")\n        df.dropna(subset=['Review', 'Class'], inplace=True) # Drop rows with NaN in critical columns\n    if df.empty: # Check again after dropping NaNs\n        raise ValueError(\"After cleaning missing values, the DataFrame is empty.\")\n\nexcept Exception as e:\n    raise Exception(f\"Error loading or processing CSV file '{csv_file}': {str(e)}\")\n\nprint(f\"Successfully loaded {len(df)} reviews from '{csv_file}'.\")\n\n# --- Task 1: Sentiment Classification ---\nprint(\"\\n--- Task 1: Sentiment Classification ---\")\n# Initialize the sentiment analysis pipeline\ntry:\n    # Using device=-1 to leverage GPU if available, otherwise CPU\n    sentiment_classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english', device=-1)\n    print(\"Sentiment classifier loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing sentiment classifier model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Classify the sentiment of each review\npredicted_labels = []\nfor i, review in enumerate(df['Review']):\n    try:\n        if not isinstance(review, str):\n            print(f\"Skipping review at index {i} due to non-string type: {type(review)}. Value: {review}\")\n            predicted_labels.append('UNKNOWN') # Or 'NEUTRAL', 'NEGATIVE' based on desired fallback\n            continue\n\n        # Truncate review if it's too long for the model (typically 512 tokens)\n        # This is a heuristic; for production, consider more advanced chunking/summarization\n        if len(review.split()) > 400: # Rough token estimate\n            review_for_model = ' '.join(review.split()[:400])\n            # print(f\"Warning: Review {i} is very long, truncating for sentiment analysis.\")\n        else:\n            review_for_model = review\n\n        result = sentiment_classifier(review_for_model)[0]['label']\n        predicted_labels.append(result)\n    except Exception as e:\n        print(f\"Error classifying review {i}: '{review[:70]}...' Error: {str(e)}. Falling back to 'NEGATIVE'.\")\n        predicted_labels.append('NEGATIVE') # Fallback to avoid breaking for individual review errors\n\n# Map predicted labels to binary {0, 1} (POSITIVE=1, NEGATIVE=0)\npredictions = [1 if label.upper() == 'POSITIVE' else 0 for label in predicted_labels]\n\n# Map ground truth labels to binary {0, 1}\ntry:\n    true_labels = []\n    for i, label in enumerate(df['Class']):\n        if isinstance(label, str):\n            true_labels.append(1 if label.upper() == 'POSITIVE' else 0)\n        else:\n            print(f\"Warning: Ground truth label at index {i} is not a string ({type(label)}). Assuming 0 (Negative). Value: {label}\")\n            true_labels.append(0) # Default for non-string ground truth labels\nexcept Exception as e:\n    raise Exception(f\"Error processing ground truth labels from 'Class' column: {str(e)}\")\n\n# Calculate accuracy and F1 score\ntry:\n    accuracy_result = accuracy_score(true_labels, predictions)\n    f1_result = f1_score(true_labels, predictions)\n    print(\"Sentiment classification metrics calculated.\")\nexcept ValueError as e:\n    print(f\"Error calculating metrics. Ensure true_labels and predictions are non-empty and compatible: {str(e)}\")\n    accuracy_result = 0.0\n    f1_result = 0.0\n\n\n# --- Task 2: Translation and BLEU Score ---\nprint(\"\\n--- Task 2: Translation and BLEU Score ---\")\n# Initialize the translation pipeline\ntry:\n    translator = pipeline('translation_en_to_es', model='Helsinki-NLP/opus-mt-en-es', device=-1)\n    print(\"Translator loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing translator model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Extract the first two sentences of the first review\ntext_to_translate = \"\"\ntry:\n    if df.empty or len(df) < 1:\n        raise ValueError(\"Cannot perform translation: DataFrame is empty or has no first review.\")\n    first_review = df['Review'].iloc[0] # Use .iloc for robust integer-based indexing\n    if not isinstance(first_review, str):\n        raise TypeError(f\"First review is not a string: {type(first_review)}. Value: {first_review}\")\n\n    sentences = nltk.sent_tokenize(first_review)\n    if len(sentences) < 2:\n        # Fallback for reviews with fewer than 2 sentences: use the whole review\n        print(f\"Warning: First review has fewer than 2 sentences ({len(sentences)}). Using the entire review for translation.\")\n        text_to_translate = ' '.join(sentences)\n        if not text_to_translate: # If the review was empty\n            raise ValueError(\"First review is empty after tokenization.\")\n    else:\n        text_to_translate = ' '.join(sentences[:2])\n    print(f\"Original text for translation: '{text_to_translate[:100]}...'\")\nexcept Exception as e:\n    raise Exception(f\"Error preparing text for translation from first review: {str(e)}\")\n\n# Perform translation\ntranslated_review = \"\"\ntry:\n    if text_to_translate: # Ensure there's something to translate\n        translation_output = translator(text_to_translate, max_length=512)\n        translated_review = translation_output[0]['translation_text']\n        print(f\"Translated text: '{translated_review[:100]}...'\")\n    else:\n        print(\"Warning: No text to translate. translated_review will be empty.\")\nexcept Exception as e:\n    raise Exception(f\"Error during translation process: {str(e)}\")\n\n# Load reference translations\nreference_translations = []\ntry:\n    with open(ref_file, 'r', encoding='utf-8') as f:\n        reference_translations = [line.strip() for line in f if line.strip()]\n    if not reference_translations:\n        raise ValueError(f\"Reference translations file '{ref_file}' is empty or contains no valid lines.\")\n    print(f\"Loaded {len(reference_translations)} reference translations.\")\nexcept Exception as e:\n    raise Exception(f\"Error loading reference translations from '{ref_file}': {str(e)}\")\n\n# Calculate BLEU score\nbleu_score = 0.0\ntry:\n    if not translated_review:\n        print(\"Cannot calculate BLEU score: translated_review is empty.\")\n    elif not reference_translations:\n        print(\"Cannot calculate BLEU score: reference_translations are empty.\")\n    else:\n        # BLEU expects a list of reference token lists, and one candidate token list\n        # So, reference_tokens should be [[ref1_words], [ref2_words], ...]\n        reference_tokens = [nltk.word_tokenize(ref) for ref in reference_translations]\n        candidate_tokens = nltk.word_tokenize(translated_review)\n        bleu_score = sentence_bleu(reference_tokens, candidate_tokens)\n        print(\"BLEU score calculated.\")\nexcept Exception as e:\n    print(f\"Error calculating BLEU score: {str(e)}. Setting BLEU to 0.0.\")\n    bleu_score = 0.0\n\n\n# --- Task 3: Extractive Question Answering ---\nprint(\"\\n--- Task 3: Extractive Question Answering ---\")\n# Initialize the QA pipeline\ntry:\n    qa_pipeline = pipeline('question-answering', model='deepset/minilm-uncased-squad2', device=-1)\n    print(\"Question-answering pipeline loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing QA pipeline model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Define question and context for the second review\nquestion = \"What did he like about the brand?\"\ncontext = \"\"\ntry:\n    if df.empty or len(df) < 2:\n        raise ValueError(\"Cannot perform QA: DataFrame has fewer than 2 reviews.\")\n    context = df['Review'].iloc[1] # Use .iloc for robust integer-based indexing\n    if not isinstance(context, str):\n        raise TypeError(f\"Second review (context for QA) is not a string: {type(context)}. Value: {context}\")\n    if not context.strip():\n        raise ValueError(\"Second review (context for QA) is empty or just whitespace.\")\n    print(f\"QA Question: '{question}'\")\n    print(f\"QA Context: '{context[:100]}...'\")\nexcept Exception as e:\n    raise Exception(f\"Error preparing context for QA from second review: {str(e)}\")\n\n# Get the answer\nanswer = \"No answer found.\"\ntry:\n    if question and context: # Ensure both are available\n        qa_result = qa_pipeline(question=question, context=context)\n        answer = qa_result['answer']\n        print(f\"QA Answer found: '{answer}'\")\n    else:\n        print(\"Warning: Question or context missing for QA. Answer will be default.\")\nexcept Exception as e:\n    print(f\"Error during Question Answering: {str(e)}. Setting answer to default.\")\n    answer = \"An error occurred while trying to find an answer.\"\n\n\n# --- Task 4: Summarization ---\nprint(\"\\n--- Task 4: Summarization ---\")\n# Initialize the summarization pipeline\ntry:\n    summarizer = pipeline('summarization', model='facebook/bart-large-cnn', device=-1)\n    print(\"Summarization pipeline loaded successfully.\")\nexcept Exception as e:\n    raise Exception(f\"Error initializing summarization model. Please check your internet connection or model name. Error: {str(e)}\")\n\n# Summarize the last review (aim for ~50-55 tokens)\nsummarized_text = \"No summary generated.\"\ntry:\n    if df.empty or len(df) < 5: # Assuming at least 5 reviews for \"last review\"\n        print(\"Warning: Not enough reviews in the dataset to summarize the last one. Skipping summarization.\")\n    else:\n        last_review = df['Review'].iloc[-1] # Use .iloc[-1] for the last review\n        if not isinstance(last_review, str):\n            raise TypeError(f\"Last review for summarization is not a string: {type(last_review)}. Value: {last_review}\")\n        if not last_review.strip():\n            raise ValueError(\"Last review for summarization is empty or just whitespace.\")\n        print(f\"Original text for summarization: '{last_review[:100]}...'\")\n\n        # Set max_length and min_length for token count control\n        # Note: These are token lengths, not word counts. 50-55 tokens is a tight range.\n        summarized = summarizer(last_review, max_length=55, min_length=50, do_sample=False)\n        summarized_text = summarized[0]['summary_text']\n        print(f\"Summarized text: '{summarized_text}'\")\nexcept Exception as e:\n    print(f\"Error during summarization: {str(e)}. Setting summary to default.\")\n    summarized_text = \"An error occurred during summarization.\"\n\n\n# --- Print Results for Verification ---\nprint(\"\\n--- Final Results ---\")\nprint(f\"Sentiment Classification Accuracy: {accuracy_result:.4f}\")\nprint(f\"Sentiment Classification F1 Score: {f1_result:.4f}\")\nprint(f\"Translated Review (English to Spanish): {translated_review}\")\nprint(f\"BLEU Score (Translation Quality): {bleu_score:.4f}\")\nprint(f\"QA Question: {question}\")\nprint(f\"QA Context (second review snippet): {context[:70]}...\")\nprint(f\"QA Answer: {answer}\")\nprint(f\"Summarized Last Review (approx. 50-55 tokens): {summarized_text}\")","outputsMetadata":{"0":{"height":185,"type":"stream"},"1":{"height":80,"type":"stream"},"2":{"height":101,"type":"stream"},"3":{"height":38,"type":"stream"},"4":{"height":80,"type":"stream"},"5":{"height":164,"type":"stream"},"6":{"height":248,"type":"stream"},"7":{"height":38,"type":"stream"},"8":{"height":80,"type":"stream"},"14":{"height":38,"type":"stream"},"15":{"height":374,"type":"stream"}}},"cell_type":"code","id":"fad6f00a-bb93-451b-aa35-cecd97d8e027","outputs":[{"output_type":"stream","name":"stdout","text":"Checking NLTK data...\n'punkt' tokenizer found.\n'wordnet' corpus not found, downloading...\n'wordnet' corpus downloaded.\nNLTK data check complete.\nSuccessfully loaded 5 reviews from 'car_reviews.csv'.\n\n--- Task 1: Sentiment Classification ---\n"},{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package wordnet to /home/repl/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nDevice set to use cpu\n"},{"output_type":"stream","name":"stdout","text":"Sentiment classifier loaded successfully.\nSentiment classification metrics calculated.\n\n--- Task 2: Translation and BLEU Score ---\n"},{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"},{"output_type":"stream","name":"stdout","text":"Translator loaded successfully.\nOriginal text for translation: 'I am very satisfied with my 2014 Nissan NV SL. I use this van for my business deliveries and persona...'\n"},{"output_type":"stream","name":"stderr","text":"Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cpu\n"},{"output_type":"stream","name":"stdout","text":"Translated text: 'Estoy muy satisfecho con mi Nissan NV SL 2014. Uso esta camioneta para mis entregas de negocios y us...'\nLoaded 2 reference translations.\nBLEU score calculated.\n\n--- Task 3: Extractive Question Answering ---\nQuestion-answering pipeline loaded successfully.\nQA Question: 'What did he like about the brand?'\nQA Context: 'The car is fine. It's a bit loud and not very powerful. On one hand, compared to its peers, the inte...'\nQA Answer found: 'ride quality, reliability'\n\n--- Task 4: Summarization ---\n"},{"output_type":"stream","name":"stderr","text":"Device set to use cpu\n"},{"output_type":"stream","name":"stdout","text":"Summarization pipeline loaded successfully.\nOriginal text for summarization: 'I've been dreaming of owning an SUV for quite a while, but I've been driving cars that were already ...'\nSummarized text: 'The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. The engine delivers strong'\n\n--- Final Results ---\nSentiment Classification Accuracy: 0.8000\nSentiment Classification F1 Score: 0.8571\nTranslated Review (English to Spanish): Estoy muy satisfecho con mi Nissan NV SL 2014. Uso esta camioneta para mis entregas de negocios y uso personal.\nBLEU Score (Translation Quality): 0.7794\nQA Question: What did he like about the brand?\nQA Context (second review snippet): The car is fine. It's a bit loud and not very powerful. On one hand, c...\nQA Answer: ride quality, reliability\nSummarized Last Review (approx. 50-55 tokens): The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. The engine delivers strong\n"}],"execution_count":18}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}